{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Optimizer\n",
        "#from adam import Adam"
      ],
      "metadata": {
        "id": "nTdXaj7PbmIi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#функция-обучения нейронной сети\n",
        "def train_loop(data, model, func_loss, optimizer):\n",
        "    size = len(data.dataset)\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch, (inputs, labels) in enumerate(data, 0):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = func_loss(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if (batch + 1) % 2000 == 0:\n",
        "            print(f\"loss: {running_loss / 2000:>7f}  [{batch + 1:>5d}/{size:>5d}]\")\n",
        "            running_loss = 0.0\n"
      ],
      "metadata": {
        "id": "vL-12wgibxF8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hWKPI0H_beS1"
      },
      "outputs": [],
      "source": [
        "#функция-тестирование нейронной сети\n",
        "def test_loop(data, model, func_loss):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (inputs, labels) in data:\n",
        "            outputs = model(inputs)\n",
        "            test_loss += func_loss(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%, loss: %.7f' % (100 * correct / total, test_loss / (total / batch_size)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#выбор гиперпараметров\n",
        "batch_size = 4\n",
        "learn_rate = 1e-3\n",
        "epoch = 10\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "oQknmw4kb3rd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Преобразование данных: перевод в тензор из PyTorch и нормализация\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#загрузка датасета\n",
        "data_train = datasets.CIFAR10(root = \"./data\", train = True, download = True, transform = transform)\n",
        "data_test = datasets.CIFAR10(root = \"./data\", train = False, download = False, transform = transform)\n",
        "#разбитие данных на партии\n",
        "dataload_train = DataLoader(data_train, batch_size = batch_size, shuffle = True)\n",
        "dataload_test = DataLoader(data_test, batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9XLAbz-b6kY",
        "outputId": "67947e91-ce7e-4be2-e3cf-9bc8675a1dfb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#представление модели нейронной сети\n",
        "class NeuralNetworks(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(6, 16, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16 * 5 * 5, 120,),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.network(input)\n",
        "        return output"
      ],
      "metadata": {
        "id": "wU1Ei8gOb97w"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Adam(Optimizer):\n",
        "    def __init__(self, param, alpha = 1e-3, beta1 = 0.9, beta2 = 0.999, eps = 1e-8):\n",
        "        self.param = list(param)\n",
        "        number_of_param = sum([par.numel() for par in self.param])\n",
        "        # print(number_of_param)\n",
        "        self.t = 0\n",
        "        self.m = [0] * number_of_param\n",
        "        self.v = [0] * number_of_param\n",
        "        defaults = dict(lr=alpha, betas=(beta1, beta2), eps=eps)\n",
        "        super().__init__(self.param, defaults)\n",
        "        # self.param = list(param)\n",
        "        # self.alpha = alpha\n",
        "        # self.beta1 = beta1\n",
        "        # self.beta2 = beta2\n",
        "        # self.eps = eps\n",
        "\n",
        "    def step(self):\n",
        "        self.t += 1\n",
        "        i = 0\n",
        "        for group in self.param_groups:\n",
        "          alpha, eps = group['lr'], group['eps']\n",
        "          beta1, beta2 = group['betas']\n",
        "          for par in group['params']:\n",
        "            gt = par.grad.data\n",
        "            self.m[i] = beta1 * self.m[i] + (1 - beta1) * gt\n",
        "            self.v[i] = beta2 * self.v[i] + (1 - beta2) * (gt ** 2)\n",
        "            mt = self.m[i] / (1 - beta1 ** self.t)\n",
        "            vt = self.v[i] / (1 - beta2 ** self.t)\n",
        "            par.data = par.data - alpha * mt / (vt ** 0.5 + eps)\n",
        "            i += 1"
      ],
      "metadata": {
        "id": "mWFNtjoocFAT"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#инициализация модели свёрточной нейронной сети, выбор функции потерь и оптимизитора\n",
        "model = NeuralNetworks()\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr = learn_rate, momentum = momentum)\n",
        "optimizer = Adam(model.parameters(), alpha = learn_rate)\n",
        "# for param in model.parameters():\n",
        "#     print(param.numel(), param.size(), param.data.numpy())\n"
      ],
      "metadata": {
        "id": "x2GTjku0cKIh"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#цикл обучения и проверки результатов обучения нейронной сети\n",
        "for ep in range(epoch):\n",
        "    print(f\"Epoch {ep + 1}\\n-------------------------------\")\n",
        "    train_loop(dataload_train, model, loss_func, optimizer)\n",
        "    test_loop(dataload_test, model, loss_func)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAcWeaTNcNT5",
        "outputId": "02cab3bb-7062-4ea0-b32e-3e040439e394"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.902140  [ 2000/50000]\n",
            "loss: 1.626977  [ 4000/50000]\n",
            "loss: 1.514962  [ 6000/50000]\n",
            "loss: 1.474470  [ 8000/50000]\n",
            "loss: 1.438166  [10000/50000]\n",
            "loss: 1.401290  [12000/50000]\n",
            "Accuracy of the network on the 10000 test images: 50 %, loss: 1.3679435\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.340068  [ 2000/50000]\n",
            "loss: 1.330802  [ 4000/50000]\n",
            "loss: 1.336162  [ 6000/50000]\n",
            "loss: 1.310423  [ 8000/50000]\n",
            "loss: 1.308589  [10000/50000]\n",
            "loss: 1.292068  [12000/50000]\n",
            "Accuracy of the network on the 10000 test images: 53 %, loss: 1.3030076\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.224545  [ 2000/50000]\n",
            "loss: 1.222666  [ 4000/50000]\n",
            "loss: 1.233755  [ 6000/50000]\n",
            "loss: 1.213878  [ 8000/50000]\n",
            "loss: 1.209254  [10000/50000]\n",
            "loss: 1.223192  [12000/50000]\n",
            "Accuracy of the network on the 10000 test images: 56 %, loss: 1.2181051\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.148077  [ 2000/50000]\n",
            "loss: 1.146092  [ 4000/50000]\n",
            "loss: 1.165533  [ 6000/50000]\n",
            "loss: 1.139503  [ 8000/50000]\n",
            "loss: 1.151765  [10000/50000]\n",
            "loss: 1.156482  [12000/50000]\n",
            "Accuracy of the network on the 10000 test images: 57 %, loss: 1.1972100\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.073598  [ 2000/50000]\n",
            "loss: 1.102436  [ 4000/50000]\n",
            "loss: 1.089104  [ 6000/50000]\n",
            "loss: 1.101067  [ 8000/50000]\n",
            "loss: 1.116442  [10000/50000]\n",
            "loss: 1.113715  [12000/50000]\n",
            "Accuracy of the network on the 10000 test images: 59 %, loss: 1.1671170\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.031942  [ 2000/50000]\n",
            "loss: 1.018615  [ 4000/50000]\n",
            "loss: 1.048296  [ 6000/50000]\n",
            "loss: 1.074816  [ 8000/50000]\n",
            "loss: 1.055710  [10000/50000]\n",
            "loss: 1.076744  [12000/50000]\n",
            "Accuracy of the network on the 10000 test images: 59 %, loss: 1.1514758\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.982365  [ 2000/50000]\n",
            "loss: 1.005163  [ 4000/50000]\n",
            "loss: 1.025296  [ 6000/50000]\n",
            "loss: 1.029523  [ 8000/50000]\n",
            "loss: 1.023061  [10000/50000]\n",
            "loss: 1.018685  [12000/50000]\n",
            "Accuracy of the network on the 10000 test images: 59 %, loss: 1.1692928\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.961044  [ 2000/50000]\n",
            "loss: 0.954462  [ 4000/50000]\n",
            "loss: 0.978075  [ 6000/50000]\n",
            "loss: 0.985419  [ 8000/50000]\n",
            "loss: 0.991036  [10000/50000]\n",
            "loss: 1.029825  [12000/50000]\n",
            "Accuracy of the network on the 10000 test images: 60 %, loss: 1.1645636\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.933256  [ 2000/50000]\n",
            "loss: 0.925497  [ 4000/50000]\n",
            "loss: 0.959965  [ 6000/50000]\n",
            "loss: 0.974336  [ 8000/50000]\n",
            "loss: 0.978235  [10000/50000]\n",
            "loss: 0.978633  [12000/50000]\n",
            "Accuracy of the network on the 10000 test images: 61 %, loss: 1.1444201\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.902696  [ 2000/50000]\n",
            "loss: 0.918455  [ 4000/50000]\n",
            "loss: 0.937201  [ 6000/50000]\n",
            "loss: 0.955423  [ 8000/50000]\n",
            "loss: 0.961131  [10000/50000]\n",
            "loss: 0.949332  [12000/50000]\n",
            "Accuracy of the network on the 10000 test images: 61 %, loss: 1.1814229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#сохранение модели\n",
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "biFG5dn8cREf",
        "outputId": "244d30d4-0209-427c-d244-816143521be6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b970beb7f61e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#сохранение модели\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}